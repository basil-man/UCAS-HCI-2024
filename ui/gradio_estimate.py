import imageio
import numpy as np
import gradio as gr
from PIL import Image
import shutil
from main import PoseEstimation, Analysis
import os
estimator = PoseEstimation()
analyzer = Analysis()


def estimate(input_video):
    return estimator(input_video)


def analyze(mode):
    return analyzer(mode)


css = """
.gradio-container {
  background-color: rgba(242, 240, 225, 1);
}
.custom-textbox {
    background-color: rgba(244, 188, 65, 0.6);
    color: black;
}
"""

with gr.Blocks() as demo:
    gr.HTML(
        """
        <div style="display: flex; justify-content: center; align-items: center; text-align: center; 
            background-color: rgba(52, 102, 165, 1); border-radius: 10px;">
            <div style="flex: 1; padding: 20px;">
                <h3 style="font-size: 2em; margin-bottom: 0.5em; color: #ffffff">äººä½“å§¿æ€ä¼°è®¡åœ¨ä½“è‚²è¿åŠ¨åŠæ•™å­¦ä¸­çš„å®è·µåº”ç”¨</h3>
                <h5 style="margin: 0.3em; color: #ffffff">âœ¨åŸºäº3Då§¿æ€ä¼°è®¡æŠ€æœ¯çš„ä½“è‚²è¿åŠ¨è‡ªåŠ¨æ•™å­¦ç³»ç»Ÿâœ¨</h5>
            </div>
        </div>
        """
    )

    with gr.Row(equal_height=True):
        with gr.Column():
            input_video = gr.Video(format="mp4", label="è¾“å…¥è§†é¢‘")
            mode = gr.Dropdown(label="åŠ¨ä½œæ¨¡å¼", choices=["æ‰£çƒğŸ", "æ‹¦ç½‘ğŸ™ŒğŸ»"])
            with gr.Row():
                submit1 = gr.Button("å§¿æ€ä¼°è®¡", elem_id="submit1")
                submit2 = gr.Button("åŠ¨ä½œåˆ†æ", elem_id="submit2")

        with gr.Column():
            estimation = gr.Video(format="mp4", label="å§¿æ€ä¼°è®¡ç»“æœ", autoplay=True, scale=1)
            analysis = gr.Textbox(label="åˆ†æç»“æœ", elem_id="analysis", scale=1)


    def read_video(video):
        video_path = video  # è·å–ä¸Šä¼ è§†é¢‘çš„ä¸´æ—¶è·¯å¾„
        save_path = "./demo/video/sample_video.mp4"  # è®¾ç½®ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å
        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # åˆ›å»ºç›®å½•
        shutil.copy(video_path, save_path)  # å¤åˆ¶æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„
        print("upload successfully!!!!")
        #reader = imageio.get_reader(video)
        #fps = reader.get_meta_data()['fps']
        return video


    def read_image(image, size=512):
        return np.array(Image.fromarray(image).resize((size, size)))


    # ä¸Šä¼ æ–°è§†é¢‘æ—¶è¿›è¡Œè¯»å–
    input_video.upload(
        read_video,
        input_video,
        input_video
    )
    # ç‚¹å‡»å§¿æ€ä¼°è®¡æŒ‰é’®
    submit1.click(
        estimate,
        input_video,
        estimation
    )
    # ç‚¹å‡»åŠ¨ä½œåˆ†ææŒ‰é’®
    submit2.click(
        analyze,
        mode,
        analysis
    )

    # ç¤ºä¾‹
    gr.Markdown("## ç¤ºä¾‹")
    gr.Examples(
        examples="demo/example/input",
        inputs=input_video,
        outputs=estimation,
    )

demo.css = css
demo.launch(share=True)
